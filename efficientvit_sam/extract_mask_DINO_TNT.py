
import os
import time
import json
import numpy as np
import torch
import cv2
from PIL import Image
from efficientvit.sam_model_zoo import create_efficientvit_sam_model
from efficientvit.models.efficientvit.sam import EfficientViTSamPredictor

# ====== PATHS ======
DTU_ROOT = "../../masked_datasets/tanks_temples"
SAM_CKPT = "./weight/efficientvit_sam_xl1.pt"

DATASET_ROOT = DTU_ROOT
OUTPUT_ROOT = DTU_ROOT
CPU_ONLY = False
TINY_AREA_RATIO = 0.0002


def pick_best_mask(masks, H, W):
    """ë©€í‹°ë§ˆìŠ¤í¬ ì¤‘ ì¤‘ì‹¬ì„± + ë©´ì  ê¸°ì¤€ìœ¼ë¡œ ìµœì  ë§ˆìŠ¤í¬ ì„ íƒ"""
    if masks.ndim == 3:
        areas = masks.reshape(masks.shape[0], -1).sum(axis=1)
        ys, xs = np.indices((H, W))
        scores = []
        for i in range(masks.shape[0]):
            m = masks[i].astype(np.float32)
            denom = m.sum() + 1e-6
            cy = (ys * m).sum() / denom
            cx = (xs * m).sum() / denom
            dist = np.sqrt((cy - H/2)**2 + (cx - W/2)**2)
            scores.append((-dist, areas[i]))
        idx = int(np.lexsort((np.array(scores)[:, 1], np.array(scores)[:, 0]))[-1])
        return masks[idx]
    return masks


def draw_overlay(image_bgr, boxes_xyxy, best_mask=None):
    vis = image_bgr.copy()
    for b in boxes_xyxy:
        cv2.rectangle(vis, (b[0], b[1]), (b[2], b[3]), (0, 255, 0), 2)
    if best_mask is not None:
        colored = np.zeros_like(vis)
        colored[:, :, 1] = (best_mask.astype(np.uint8) * 180)
        vis = cv2.addWeighted(vis, 1.0, colored, 0.4, 0)
    return vis


def process_scan(scan_name, predictor):
    """ê° scan í´ë”ì˜ bbox JSONì„ ë¶ˆëŸ¬ì™€ SAMìœ¼ë¡œ ë§ˆìŠ¤í¬ ìƒì„±"""
    scan_path = os.path.join(DATASET_ROOT, scan_name)
    image_dir = os.path.join(scan_path, "images")
    label_dir = os.path.join(scan_path, "labels")
    output_dir = os.path.join(OUTPUT_ROOT, scan_name, "masks")

    if not os.path.exists(image_dir):
        print(f"[WARN] {scan_name}: images í´ë” ì—†ìŒ. ê±´ë„ˆëœ€.")
        return
    if not os.path.exists(label_dir):
        print(f"[WARN] {scan_name}: labels í´ë” ì—†ìŒ. ê±´ë„ˆëœ€.")
        return

    os.makedirs(output_dir, exist_ok=True)

    img_files = sorted([f for f in os.listdir(image_dir) if f.lower().endswith((".png", ".jpg", ".jpeg"))])
    print(f"[{scan_name}] {len(img_files)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...")

    total_time, cnt = 0.0, 0

    for fname in img_files:
        name, _ = os.path.splitext(fname)
        json_path = os.path.join(label_dir, f"{name}_bbox.json")
        img_path = os.path.join(image_dir, fname)
        out_mask_path = os.path.join(output_dir, f"{name}_mask.png")
        # out_overlay_path = os.path.join(output_dir, f"{name}_overlay.jpg")

        if os.path.exists(out_mask_path):
            print(f"â­ï¸ {fname}: ì´ë¯¸ ë§ˆìŠ¤í¬ ì¡´ì¬ â†’ ê±´ë„ˆëœ€.")
            continue
        
        if not os.path.exists(json_path):
            print(f"âš ï¸ {fname}: bbox json ì—†ìŒ â†’ ê±´ë„ˆëœ€.")
            continue

        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        bboxes = data.get("bboxes", [])
        if not bboxes:
            print(f"âš ï¸ {fname}: bbox ì •ë³´ ì—†ìŒ â†’ ê±´ë„ˆëœ€.")
            continue

        img_bgr = cv2.imread(img_path)
        if img_bgr is None:
            print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŒ: {img_path}")
            continue

        H, W = img_bgr.shape[:2]
        predictor.set_image(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))

        found = False
        t0 = time.time()

        # bbox ë¦¬ìŠ¤íŠ¸ ë°˜ë³µ (í•˜ë‚˜ë§Œ ìˆì–´ë„ ë™ì‘)
        for box in bboxes:
            b = np.array([box["x1"], box["y1"], box["x2"], box["y2"]])
            masks, _, _ = predictor.predict(box=b, multimask_output=True)
            mask = pick_best_mask(masks, H, W)
            mask_u8 = (mask.astype(np.uint8)) * 255

            # ë„ˆë¬´ ì‘ì€ ë§ˆìŠ¤í¬ëŠ” ë¬´ì‹œ
            if mask_u8.sum() < TINY_AREA_RATIO * (H * W) * 255:
                continue

            cv2.imwrite(out_mask_path, mask_u8)
            overlay = draw_overlay(img_bgr, [b], best_mask=mask)
            # cv2.imwrite(out_overlay_path, overlay)
            print(f"âœ… {scan_name}: Saved mask for {fname}")
            found = True
            break

        if not found:
            black = np.zeros((H, W), dtype=np.uint8)
            cv2.imwrite(out_mask_path, black)
            print(f"âŒ {scan_name}: No valid mask for {fname}")

        total_time += time.time() - t0
        cnt += 1

    print(f"[{scan_name}] í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_time / max(cnt, 1):.2f}s")


def main():
    os.makedirs(OUTPUT_ROOT, exist_ok=True)
    device = "cuda" if (torch.cuda.is_available() and not CPU_ONLY) else "cpu"
    torch.set_grad_enabled(False)
    torch.backends.cudnn.benchmark = True

    print("ğŸ§  SAM ëª¨ë¸ ë¡œë“œ ì¤‘...")
    sam = create_efficientvit_sam_model("efficientvit-sam-xl1", pretrained=False)
    sam.load_state_dict(torch.load(SAM_CKPT, map_location=device))
    sam = sam.to(device).eval()
    predictor = EfficientViTSamPredictor(sam)
    print("âœ… SAM ë¡œë“œ ì™„ë£Œ\n")

    # target=['Barn', 'Truck']

    # ëª¨ë“  scan í´ë” ìˆœíšŒ
    for scan_name in sorted(os.listdir(DATASET_ROOT)):
        # if scan_name not in target:
        #     continue
        if not os.path.isdir(os.path.join(DATASET_ROOT, scan_name)):
            continue
        process_scan(scan_name, predictor)

    print("\nğŸ‰ ëª¨ë“  scan ì²˜ë¦¬ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
